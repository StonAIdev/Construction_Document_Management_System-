cluster_name: "StonAI"
# max_workers: 7
min_workers: 1
max_workers: 10
upscaling_speed: 1.3
idle_timeout_minutes: 5
autoscaling_mode: default
provider:
    type: aws
    region: ap-south-1
    # Availability zone(s), comma-separated, that nodes may be launched in.
    # Nodes are currently spread between zones by a round-robin approach,
    # however this implementation detail should not be relied upon.
    availability_zone: ap-south-1a,ap-south-1b,ap-south-1c
    # Whether to allow node reuse. If set to False, nodes will be terminated
    # instead of stopped.
    # cache_stopped_nodes: False # If not present, the default is True.
    use_internal_ips: True
auth:
    ssh_user: ubuntu
    # ssh_private_key: "./Waqar/MumbaiKey.ppk"
# head_node:
#         InstanceType: m5.xlarge
#         ImageId: ami-0567e0d2b4b2169ae # Ubuntu 20 ami

#         # You can provision additional disk space with a conf as follows
#         # BlockDeviceMappings:
#         #     - DeviceName: /dev/sda1
#         #     Ebs:
#         #         VolumeSize: 100
# worker_nodes:
#         InstanceType: m5.xlarge
#         ImageId: ami-0567e0d2b4b2169ae # Ubuntu 20 ami
#         SubnetId:  subnet-0fbd729502dee2430

#         # You can provision additional disk space with a conf as follows
#         # BlockDeviceMappings:
#         #     - DeviceName: /dev/sda1
#         #     Ebs:
#         #         VolumeSize: 100
available_node_types:
    ray.head.default:
        # The node type's CPU and GPU resources are auto-detected based on AWS instance type.
        # If desired, you can override the autodetected CPU and GPU resources advertised to the autoscaler.
        # You can also set custom resources.
        # For example, to mark a node type as having 1 CPU, 1 GPU, and 5 units of a resource called "custom", set
        # resources: {"CPU": 1, "GPU": 1, "custom": 5}
        resources: {}
        min_workers: 1
        # max_workers: 1
        # Provider-specific config for this node type, e.g. instance type. By default
        # Ray will auto-configure unspecified fields such as SubnetId and KeyName.
        # For more documentation on available fields, see:
        # http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.ServiceResource.create_instances
        
        node_config:
            # KeyName: Ray_dummy_head_key
            # KeyName: default
            # InstanceType: m5.xlarge
            InstanceType: t3a.2xlarge
            ImageId: ami-0ecb7f94cf810276f #ami-0a6934ef7c6febfbc #ami-032c7b9cb81f3cc2f #ami-07cc357db1719b70c # Ubuntu 20 ami
            SecurityGroupIds: ["sg-00829f8ae57496119"]
            # SubnetIds:  ["subnet-0fbd729502dee2430"]
            # You can provision additional disk space with a conf as follows
            BlockDeviceMappings:
                - DeviceName: /dev/sda1
                  Ebs:
                      VolumeSize: 100
            # Additional options in the boto docs.
    ray.worker.default:
        # The minimum number of worker nodes of this type to launch.
        # This number should be >= 0.
        min_workers: 0
        # The maximum number of worker nodes of this type to launch.
        # This takes precedence over min_workers.
        max_workers: 3
        # The node type's CPU and GPU resources are auto-detected based on AWS instance type.
        # If desired, you can override the autodetected CPU and GPU resources advertised to the autoscaler.
        # You can also set custom resources.
        # For example, to mark a node type as having 1 CPU, 1 GPU, and 5 units of a resource called "custom", set
        # resources: {"CPU": 1, "GPU": 1, "custom": 5}
        resources: {}
        # Provider-specific config for this node type, e.g. instance type. By default
        # Ray will auto-configure unspecified fields such as SubnetId and KeyName.
        # For more documentation on available fields, see:
        # http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.ServiceResource.create_instances
        node_config:
            InstanceType: t3a.2xlarge
            ImageId: ami-0ecb7f94cf810276f #ami-0a6934ef7c6febfbc #ami-032c7b9cb81f3cc2f #ami-07cc357db1719b70c # Ubuntu 20 ami
            # Run workers on spot by default. Comment this out to use on-demand.
            # KeyName: Ray_dummy_node_key
            # KeyName: default
            SecurityGroupIds: ["sg-00829f8ae57496119"]
            # SubnetIds:  ["subnet-0fbd729502dee2430"]
            InstanceMarketOptions:
                MarketType: spot
                # Additional options can be found in the boto docs, e.g.
                #   SpotOptions:
                #       MaxPrice: MAX_HOURLY_PRICE
            # Additional options in the boto docs.
            # You can provision additional disk space with a conf as follows
            BlockDeviceMappings:
                - DeviceName: /dev/sda1
                  Ebs:
                      VolumeSize: 100

# Specify the node type of the head node (as configured above).
head_node_type: ray.head.default

file_mounts:
    {}
cluster_synced_files:
    []
# rsync_exclude:
#     - str
# rsync_filter:
#     - str
# initialization_commands:
#     - str
# setup_commands:
    # ["sudo apt-get update","python3 --version","sudo apt-get -o DPkg::Lock::Timeout=-1 install aptdaemon","sudo aptdcon --install python3-pip","sudo aptdcon --install python-pip","alias pip='pip3'","sudo -H pip3 install --upgrade pip","sudo pip3 install --ignore-installed PyYAML","sudo pip3 install -U ray[all]"]
setup_commands:
    [
        ' sudo rm -rf StonAI-Smart-Extraction'
        ,' sudo apt-get install -y poppler-utils'
        ,' pip3 install --upgrade ray[all]==2.0.0'
        ,' pip3 install pydantic==1.10.9'
        # NOTE: Token removed. Use environment-based auth or a deploy key instead.
        ,' git clone https://github.com/MrKhan96/StonAI-Smart-Extraction.git'
        ,' cd StonAI-Smart-Extraction'
        ,' ls'
        ,' pip3 install flask'
        # ,' pip3 install langchain'
        # ,' pip3 install tiktoken'
        # ,' pip3 install python-dotenv'
        ,' pip3 install fuzzywuzzy'
        ,' pip3 install gunicorn'
        ,' pip3 install elasticsearch'
        ,' pip3 install pdf2image'
        ,' pip install pdfminer'
        ,' pip3 install pdfplumber'
        ,' pip3 install transformers[torch]'
        ,' pip3 install opencv-contrib-python'
        ,' pip3 install pymupdf'
        ,' pip3 install nltk'
        # ,' pip3 install sklearn'
        ,' pip3 install date-extractor'
        ,' pip3 install spacy'
        ,' pip3 install gdown'
        ,' pip3 install --upgrade azure-ai-formrecognizer'
        # ,' python3 /home/ubuntu/StonAI-Smart-Extraction/downloadModel.py'
        # ,' pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu'
        ,' ls'
    ]
head_setup_commands:
    []
#     - str
worker_setup_commands:
    []
#     - str
head_start_ray_commands:
    []
#     - str

head_start_ray_commands:
    - ray stop
    # - rm -rf StonAI-Smart-Extraction
    - git -C "StonAI-Smart-Extraction" pull
    - python3 --version
    # - python3 StonAI-Smart-Extraction/trainModel.py
    # - git clone https://github.com/MrKhan96/StonAI-Smart-Extraction.git
    # - cd StonAI-Smart-Extraction
    # - ls
    # - pip3 install flask
    # - pip3 install elasticsearch
    # - pip3 install pdf2image
    # - pip install pdfminer
    # - pip3 install pdfplumber
    # - pip3 install transformers[torch]
    # - pip3 install opencv-contrib-python
    # - pip3 install --upgrade pymupdf  
    # - pip3 install nltk
    # - pip3 install sklearn
    - ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=/home/ubuntu/StonAI-Smart-Extraction/ray_cluster.yaml --include-dashboard=True --dashboard-host=0.0.0.0 --dashboard-port=8266
    # - sudo systemctl stop flaskAPI
    # - sudo systemctl disable flaskAPI
    # - sudo systemctl daemon-reload
    # - sudo systemctl stop nginx
    # - sudo systemctl disable nginx
    # - sudo systemctl enable flaskAPI
    - ls
    - python3 StonAI-Smart-Extraction/ServeFastAPI.py
    # - sudo systemctl status flaskAPI
    # - sudo apt-get install libgl1
    # - sudo aptdcon --install libgl1
    # - python3 StonAI-Smart-Extraction/rayServeTest.py

# Command to start ray on worker nodes. You don't need to change this.
worker_start_ray_commands:
    - ray stop
    - ray start --address=$RAY_HEAD_IP:6379 --object-manager-port=8076
    # - sudo apt-get install libgl1
    # - pip3 install flask
    # - pip3 install elasticsearch
    # - pip3 install pdf2image
    # - pip install pdfminer
    # - pip3 install pdfplumber
    # - pip3 install transformers[torch]
    # - pip3 install opencv-contrib-python
    # - pip3 install --upgrade pymupdf
    # - pip3 install nltk
    # - pip3 install sklearn
    # - sudo aptdcon --install libgl1
